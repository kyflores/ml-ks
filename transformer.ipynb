{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea98109-5559-4d4f-b1b0-fe7a090b98ee",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "The goal of this notebook is to create an educational implementation of the transformer with minimal dependencies that's easy to map to the paper.\n",
    "\n",
    "### References\n",
    "https://github.com/pytorch/examples/blob/main/word_language_model/\n",
    "\n",
    "https://github.com/karpathy/nanoGPT/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6daf62f3-68f0-4c07-ad7d-640638897d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b4fc8a-31d1-490a-ad50-be68a6433734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, positions, vocab_size, dmodel):\n",
    "        super().__init__()\n",
    "        self.word_embs = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=dmodel\n",
    "        )\n",
    "        # TODO when we have a more interesting dataset compare sinusoid vs learnable embeddings\n",
    "        p_grid, i_grid = torch.meshgrid(\n",
    "            torch.arange(positions),\n",
    "            torch.arange(dmodel),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        self.register_buffer('pos_sin', torch.sin(p_grid / (10000**(2 * i_grid / dmodel))))\n",
    "        self.register_buffer('pos_cos', torch.cos(p_grid / (10000**(2 * i_grid / dmodel))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.word_embs(x)\n",
    "        e = (e + self.pos_sin + self.pos_cos)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864bf314-06d2-4c41-9f42-645b9c4d810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs q,k,v are positions x dk, or positions x dv\n",
    "# Dot all q with k. One must be tranposed to make this line up\n",
    "class SDPA(nn.Module):\n",
    "    def __init__(self, causal, positions, dkv):\n",
    "        super().__init__()\n",
    "        self.pos = positions\n",
    "        self.d = dkv\n",
    "        self.causal = causal\n",
    "        if causal:\n",
    "            self.register_buffer('mask', torch.tril(torch.ones(self.pos, self.pos)))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, q, k, v):\n",
    "        assert(self.d == k.shape[-1])\n",
    "        q_dot_k = torch.bmm(q, (k.transpose(-2, -1)))\n",
    "        scaled = q_dot_k / (math.sqrt(self.d))\n",
    "        if self.causal:\n",
    "            # TODO is this an elementwise or a matmul?\n",
    "            # scaled = torch.bmm(scaled, self.mask.expand(q.shape[0], self.pos, self.pos)) \n",
    "            scaled = scaled * self.mask\n",
    "        logits = self.softmax(scaled)\n",
    "        out = torch.bmm(logits, v)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54606881-b708-4322-a171-74e963c4113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, causal, positions, dkv, dmodel):\n",
    "        super().__init__()\n",
    "        self.v_projection = nn.Linear(dmodel, dkv)\n",
    "        self.k_projection = nn.Linear(dmodel, dkv)\n",
    "        self.q_projection = nn.Linear(dmodel, dkv)\n",
    "\n",
    "        self.sdpa = SDPA(causal, positions, dkv)\n",
    "\n",
    "    def forward(self, v, k, q):\n",
    "        vp = self.v_projection(v)\n",
    "        kp = self.k_projection(k)\n",
    "        qp = self.q_projection(q)\n",
    "        return self.sdpa(qp, kp, vp)\n",
    "\n",
    "# dk = dv = dmodel/nhead\n",
    "# wq is dmodel x dk\n",
    "# wk is dmodel x dk\n",
    "# wv is dmodel x dv\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, causal, positions, nhead, dmodel):\n",
    "        super().__init__()\n",
    "        assert(dmodel % nhead == 0)\n",
    "        self.heads = nn.ModuleList([Head(causal, positions, dmodel//nhead, dmodel) for _ in range(nhead)])\n",
    "        \n",
    "        # TODO In the paper it's called WO, and hd_v x dmodel, but b/c d_v = dmodel/h it turns out to be square.\n",
    "        self.out_projection = nn.Linear(dmodel, dmodel)\n",
    "\n",
    "    def forward(self, v, k, q):\n",
    "        head_outputs = [h(v, k, q) for h in self.heads]\n",
    "        catd = torch.cat(head_outputs, dim=-1)\n",
    "        \n",
    "        projection = self.out_projection(catd)\n",
    "        return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a292bdcd-aec6-4586-947f-87ffa39dbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dmodel, ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.f0 = nn.Linear(dmodel, ff)\n",
    "        self.f1 = nn.Linear(ff, dmodel)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f0(x)\n",
    "        x = self.act(x)\n",
    "        x = self.f1(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Input/Output are Batch, Positions, then Model Dimension.\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, positions, dmodel, ff, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mha0 = MHA(True, positions, nhead, dmodel)\n",
    "        self.layernorm0 = nn.LayerNorm(dmodel)\n",
    "        self.mha1 = MHA(True, positions, nhead, dmodel)\n",
    "        self.layernorm1 = nn.LayerNorm(dmodel)\n",
    "        self.feedforward = FeedForward(dmodel, ff, dropout)\n",
    "        self.layernorm2 = nn.LayerNorm(dmodel)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, inputs, cross=None): \n",
    "        x = self.mha0(inputs, inputs, inputs)\n",
    "        x = self.layernorm0(x + inputs)\n",
    "\n",
    "        x_pre_mha1 = x\n",
    "        if cross is not None:\n",
    "            x = self.mha1(cross, cross, x)\n",
    "        else:\n",
    "            x = self.mha1(x, x, x)\n",
    "        x = self.layernorm1(x + x_pre_mha1)\n",
    "\n",
    "        x_pre_ff = x\n",
    "        x = self.feedforward(x)\n",
    "        x = self.layernorm2(x + x_pre_ff)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00183a5-6513-4e7d-9062-c49a585ee372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputProjection(nn.Module):\n",
    "    def __init__(self, dmodel, vocab_size):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dmodel, vocab_size)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "\n",
    "        # You'd expect a softmax here, but we're leaving it out and going to let CrossEntropyLoss handle it instead.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baad6818-a576-41a8-b47e-a22e6cf715cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, positions, dmodel, ff, nhead, nlayers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = Embeddings(positions, vocab_size, dmodel)\n",
    "        self.transformer_layers = nn.ModuleList([TransformerDecoder(positions, dmodel, ff, nhead=nhead, dropout=dropout) for _ in range(nlayers)])\n",
    "        self.out = OutputProjection(dmodel, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b860c9-97d5-4a98-8e6a-1674e3712161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/karpathy/minGPT/blob/master/demo.ipynb\n",
    "# Contrived dataset to show that our transformer kind of works.\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import pickle\n",
    "\n",
    "class SortDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Sort problem. E.g. for problem length 6:\n",
    "    Input: 0 0 2 1 0 1 -> Output: 0 0 0 1 1 2\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:  0 0 2 1 0 1 0 0 0 1 1\n",
    "    output: I I I I I 0 0 0 1 1 2\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=6, num_digits=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "        self.num_digits = num_digits\n",
    "    def __len__(self):\n",
    "        return 10000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return self.num_digits\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return self.length * 2 - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # use rejection sampling to generate an input example from the desired split\n",
    "        while True:\n",
    "            # generate some random integers\n",
    "            inp = torch.randint(self.num_digits, size=(self.length,), dtype=torch.long)\n",
    "            # half of the time let's try to boost the number of examples that \n",
    "            # have a large number of repeats, as this is what the model seems to struggle\n",
    "            # with later in training, and they are kind of rate\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                if inp.unique().nelement() > self.length // 2:\n",
    "                    # too many unqiue digits, re-sample\n",
    "                    continue\n",
    "            # figure out if this generated example is train or test based on its hash\n",
    "            h = hash(pickle.dumps(inp.tolist()))\n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        # solve the task: i.e. sort\n",
    "        sol = torch.sort(inp)[0]\n",
    "\n",
    "        # concatenate the problem specification and the solution\n",
    "        cat = torch.cat((inp, sol), dim=0)\n",
    "\n",
    "        # the inputs to the transformer will be the offset sequence\n",
    "        x = cat[:-1].clone()\n",
    "        y = cat[1:].clone()\n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        y[:self.length-1] = -1\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2c9958-d737-42b6-a4c3-eeb15dc4577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 256\n",
    "length = 6\n",
    "num_digits = 5\n",
    "dset_train = SortDataset(split='train', length=length, num_digits=num_digits)\n",
    "dset_test = SortDataset(split='test', length=length, num_digits=num_digits)\n",
    "train_loader = DataLoader(dset_train, batch_size=batchsize, num_workers=4, shuffle=True)\n",
    "test_loader = DataLoader(dset_train, batch_size=batchsize, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b74fcc-e28b-4a33-a99b-2113e5a096c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel = 64\n",
    "positions = dset_train.get_block_size()\n",
    "vocab_size = dset_train.get_vocab_size()\n",
    "ff = 4 * dmodel\n",
    "heads_per_layer = 4\n",
    "layers = 4\n",
    "\n",
    "model = Transformer(vocab_size, positions, dmodel, ff, heads_per_layer, layers, 0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a274c92e-c1dc-454b-8724-a2a40ae6e16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Current loss is 1.5419299602508545\n",
      "Epoch 1, Current loss is 1.2285696268081665\n",
      "Epoch 2, Current loss is 0.9946413040161133\n",
      "Epoch 3, Current loss is 0.8747833371162415\n",
      "Epoch 4, Current loss is 0.8284615278244019\n",
      "Epoch 5, Current loss is 0.8142078518867493\n",
      "Epoch 6, Current loss is 0.8120526075363159\n",
      "Epoch 7, Current loss is 0.8052729368209839\n",
      "Epoch 8, Current loss is 0.8070975542068481\n",
      "Epoch 9, Current loss is 0.805962085723877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7977c9f43010>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_plot = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (text, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # We take the last \"length\" digits so that the network is trained to replicate these from the input.\n",
    "        # It's not really necessary, it work also work to only calculate loss from the last digit, which is the actual prediction.\n",
    "        targets = F.one_hot(target[..., -length:], num_classes=num_digits).to(device, dtype=torch.float32)\n",
    "        outs = model(text.to(device))\n",
    "        loss = lossfn(outs[..., -length:, :], targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    for i, (text, target) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            targets = F.one_hot(target[..., -length:], num_classes=num_digits).to(device, dtype=torch.float32)\n",
    "            outs = model(text.to(device))\n",
    "            loss = lossfn(outs[..., -length:, :], targets)\n",
    "            losses.append(loss)\n",
    "\n",
    "    epoch_loss = torch.Tensor(losses).mean().item()\n",
    "    print(\"Epoch {}, Current loss is {}\".format(epoch, epoch_loss))\n",
    "    loss_plot.append(epoch_loss)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4a55b5-959c-4815-9edc-827e391cb582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probs tensor([[0.9912, 0.0031, 0.0012, 0.0017, 0.0029],\n",
      "        [0.0021, 0.9855, 0.0077, 0.0028, 0.0020],\n",
      "        [0.0017, 0.0021, 0.9934, 0.0016, 0.0012],\n",
      "        [0.0029, 0.0040, 0.0016, 0.9899, 0.0016],\n",
      "        [0.0027, 0.0041, 0.0012, 0.9901, 0.0018],\n",
      "        [0.0038, 0.0016, 0.0019, 0.0039, 0.9888]])\n",
      "Sorted tensor([0, 1, 2, 3, 3, 4])\n",
      "\n",
      "Probs tensor([[9.8638e-01, 7.3614e-03, 7.4504e-04, 2.5878e-03, 2.9237e-03],\n",
      "        [2.8105e-03, 9.8565e-01, 2.4245e-03, 5.5719e-03, 3.5457e-03],\n",
      "        [1.8205e-03, 9.8594e-01, 5.9732e-03, 4.0142e-03, 2.2481e-03],\n",
      "        [8.9554e-04, 2.6721e-03, 9.9301e-01, 1.2007e-03, 2.2167e-03],\n",
      "        [2.0465e-03, 1.4393e-03, 9.9303e-01, 1.2714e-03, 2.2099e-03],\n",
      "        [8.3293e-04, 1.8771e-03, 9.8497e-01, 4.8574e-03, 7.4656e-03]])\n",
      "Sorted tensor([0, 1, 1, 2, 2, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    a = torch.tensor([[0, 1, 3, 4, 3, 2,    0, 1, 2, 3, 3]]) # Next digit is 4\n",
    "    out = model(a.to(device))\n",
    "    z = F.softmax(out[0, -length:, :], dim=-1)\n",
    "    print(\"Probs {}\\nSorted {}\\n\".format(z.cpu(), torch.argmax(z, dim=-1).cpu()))\n",
    "\n",
    "    a = torch.tensor([[0, 1, 2, 2, 1, 2,    0, 1, 1, 2, 2]]) # Next digit is 2\n",
    "    out = model(a.to(device))\n",
    "    z = F.softmax(out[0, -length:, :], dim=-1)\n",
    "    print(\"Probs {}\\nSorted {}\\n\".format(z.cpu(), torch.argmax(z, dim=-1).cpu()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960dc0fa-6b04-4b9d-b270-03f2fc02a104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
