{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea98109-5559-4d4f-b1b0-fe7a090b98ee",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "The goal of this notebook is to create an educational implementation of the transformer with minimal dependencies that's easy to map to the paper.\n",
    "\n",
    "### References\n",
    "https://github.com/pytorch/examples/blob/main/word_language_model/\n",
    "\n",
    "https://github.com/karpathy/nanoGPT/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6daf62f3-68f0-4c07-ad7d-640638897d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b4fc8a-31d1-490a-ad50-be68a6433734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, positions, vocab_size, dmodel):\n",
    "        super().__init__()\n",
    "        self.word_embs = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=dmodel\n",
    "        )\n",
    "        # TODO when we have a more interesting dataset compare sinusoid vs learnable embeddings\n",
    "        p_grid, i_grid = torch.meshgrid(\n",
    "            torch.arange(positions),\n",
    "            torch.arange(dmodel),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        self.register_buffer('pos_sin', torch.sin(p_grid / (10000**(2 * i_grid / dmodel))))\n",
    "        self.register_buffer('pos_cos', torch.cos(p_grid / (10000**(2 * i_grid / dmodel))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.word_embs(x)\n",
    "        e = (e + self.pos_sin + self.pos_cos)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864bf314-06d2-4c41-9f42-645b9c4d810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs q,k,v are positions x dk, or positions x dv\n",
    "# Dot all q with k. One must be tranposed to make this line up\n",
    "class SDPA(nn.Module):\n",
    "    def __init__(self, causal, positions, dkv):\n",
    "        super().__init__()\n",
    "        self.pos = positions\n",
    "        self.d = dkv\n",
    "        self.causal = causal\n",
    "        if causal:\n",
    "            self.register_buffer('mask', torch.tril(torch.ones(self.pos, self.pos)))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, q, k, v):\n",
    "        assert(self.d == k.shape[-1])\n",
    "        q_dot_k = torch.bmm(q, (k.transpose(-2, -1)))\n",
    "        scaled = q_dot_k / (math.sqrt(self.d))\n",
    "        if self.causal:\n",
    "            # TODO is this an elementwise or a matmul?\n",
    "            # scaled = torch.bmm(scaled, self.mask.expand(q.shape[0], self.pos, self.pos)) \n",
    "            scaled = scaled * self.mask\n",
    "        logits = self.softmax(scaled)\n",
    "        out = torch.bmm(logits, v)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54606881-b708-4322-a171-74e963c4113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, causal, positions, dkv, dmodel):\n",
    "        super().__init__()\n",
    "        self.v_projection = nn.Linear(dmodel, dkv)\n",
    "        self.k_projection = nn.Linear(dmodel, dkv)\n",
    "        self.q_projection = nn.Linear(dmodel, dkv)\n",
    "\n",
    "        self.sdpa = SDPA(causal, positions, dkv)\n",
    "\n",
    "    def forward(self, v, k, q):\n",
    "        vp = self.v_projection(v)\n",
    "        kp = self.k_projection(k)\n",
    "        qp = self.q_projection(q)\n",
    "        return self.sdpa(qp, kp, vp)\n",
    "\n",
    "# dk = dv = dmodel/nhead\n",
    "# wq is dmodel x dk\n",
    "# wk is dmodel x dk\n",
    "# wv is dmodel x dv\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, causal, positions, nhead, dmodel):\n",
    "        super().__init__()\n",
    "        assert(dmodel % nhead == 0)\n",
    "        self.heads = nn.ModuleList([Head(causal, positions, dmodel//nhead, dmodel) for _ in range(nhead)])\n",
    "        \n",
    "        # TODO In the paper it's called WO, and hd_v x dmodel, but b/c d_v = dmodel/h it turns out to be square.\n",
    "        self.out_projection = nn.Linear(dmodel, dmodel)\n",
    "\n",
    "    def forward(self, v, k, q):\n",
    "        head_outputs = [h(v, k, q) for h in self.heads]\n",
    "        catd = torch.cat(head_outputs, dim=-1)\n",
    "        \n",
    "        projection = self.out_projection(catd)\n",
    "        return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a292bdcd-aec6-4586-947f-87ffa39dbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dmodel, ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.f0 = nn.Linear(dmodel, ff)\n",
    "        self.f1 = nn.Linear(ff, dmodel)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f0(x)\n",
    "        x = self.act(x)\n",
    "        x = self.f1(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Input/Output are Batch, Positions, then Model Dimension.\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, positions, dmodel, ff, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mha0 = MHA(True, positions, nhead, dmodel)\n",
    "        self.layernorm0 = nn.LayerNorm(dmodel)\n",
    "        self.mha1 = MHA(True, positions, nhead, dmodel)\n",
    "        self.layernorm1 = nn.LayerNorm(dmodel)\n",
    "        self.feedforward = FeedForward(dmodel, ff, dropout)\n",
    "        self.layernorm2 = nn.LayerNorm(dmodel)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, inputs, cross=None): \n",
    "        x = self.mha0(inputs, inputs, inputs)\n",
    "        x = self.layernorm0(x + inputs)\n",
    "\n",
    "        x_pre_mha1 = x\n",
    "        if cross is not None:\n",
    "            x = self.mha1(cross, cross, x)\n",
    "        else:\n",
    "            x = self.mha1(x, x, x)\n",
    "        x = self.layernorm1(x + x_pre_mha1)\n",
    "\n",
    "        x_pre_ff = x\n",
    "        x = self.feedforward(x)\n",
    "        x = self.layernorm2(x + x_pre_ff)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00183a5-6513-4e7d-9062-c49a585ee372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputProjection(nn.Module):\n",
    "    def __init__(self, dmodel, vocab_size):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dmodel, vocab_size)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "\n",
    "        # You'd expect a softmax here, but we're leaving it out and going to let CrossEntropyLoss handle it instead.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baad6818-a576-41a8-b47e-a22e6cf715cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, positions, dmodel, ff, nhead, nlayers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = Embeddings(positions, vocab_size, dmodel)\n",
    "        self.transformer_layers = nn.ModuleList([TransformerDecoder(positions, dmodel, ff, nhead=nhead, dropout=dropout) for _ in range(nlayers)])\n",
    "        self.out = OutputProjection(dmodel, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b860c9-97d5-4a98-8e6a-1674e3712161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/karpathy/minGPT/blob/master/demo.ipynb\n",
    "# Contrived dataset to show that our transformer kind of works.\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import pickle\n",
    "\n",
    "class SortDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Sort problem. E.g. for problem length 6:\n",
    "    Input: 0 0 2 1 0 1 -> Output: 0 0 0 1 1 2\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:  0 0 2 1 0 1 0 0 0 1 1\n",
    "    output: I I I I I 0 0 0 1 1 2\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=6, num_digits=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "        self.num_digits = num_digits\n",
    "    def __len__(self):\n",
    "        return 10000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return self.num_digits\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return self.length * 2 - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # use rejection sampling to generate an input example from the desired split\n",
    "        while True:\n",
    "            # generate some random integers\n",
    "            inp = torch.randint(self.num_digits, size=(self.length,), dtype=torch.long)\n",
    "            # half of the time let's try to boost the number of examples that \n",
    "            # have a large number of repeats, as this is what the model seems to struggle\n",
    "            # with later in training, and they are kind of rate\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                if inp.unique().nelement() > self.length // 2:\n",
    "                    # too many unqiue digits, re-sample\n",
    "                    continue\n",
    "            # figure out if this generated example is train or test based on its hash\n",
    "            h = hash(pickle.dumps(inp.tolist()))\n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        # solve the task: i.e. sort\n",
    "        sol = torch.sort(inp)[0]\n",
    "\n",
    "        # concatenate the problem specification and the solution\n",
    "        cat = torch.cat((inp, sol), dim=0)\n",
    "\n",
    "        # the inputs to the transformer will be the offset sequence\n",
    "        x = cat[:-1].clone()\n",
    "        y = cat[1:].clone()\n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        y[:self.length-1] = -1\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2c9958-d737-42b6-a4c3-eeb15dc4577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 256\n",
    "length = 6\n",
    "num_digits = 5\n",
    "dset_train = SortDataset(split='train', length=length, num_digits=num_digits)\n",
    "dset_test = SortDataset(split='test', length=length, num_digits=num_digits)\n",
    "train_loader = DataLoader(dset_train, batch_size=batchsize, num_workers=4, shuffle=True)\n",
    "test_loader = DataLoader(dset_test, batch_size=batchsize, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b74fcc-e28b-4a33-a99b-2113e5a096c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel = 64\n",
    "positions = dset_train.get_block_size()\n",
    "vocab_size = dset_train.get_vocab_size()\n",
    "ff = 4 * dmodel\n",
    "heads_per_layer = 4\n",
    "layers = 4\n",
    "\n",
    "model = Transformer(vocab_size, positions, dmodel, ff, heads_per_layer, layers, 0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a274c92e-c1dc-454b-8724-a2a40ae6e16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Current loss is 1.595977783203125\n",
      "Epoch 1, Current loss is 1.2449209690093994\n",
      "Epoch 2, Current loss is 1.011880874633789\n",
      "Epoch 3, Current loss is 0.8803423643112183\n",
      "Epoch 4, Current loss is 0.8338440656661987\n",
      "Epoch 5, Current loss is 0.8183137774467468\n",
      "Epoch 6, Current loss is 0.8087917566299438\n",
      "Epoch 7, Current loss is 0.7970739006996155\n",
      "Epoch 8, Current loss is 0.8036062121391296\n",
      "Epoch 9, Current loss is 0.8004189729690552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7dd29c61fdd0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_plot = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (text, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # We take the last \"length\" digits so that the network is trained to replicate these from the input.\n",
    "        # It's not really necessary, it work also work to only calculate loss from the last digit, which is the actual prediction.\n",
    "        targets = F.one_hot(target[..., -length:], num_classes=num_digits).to(device, dtype=torch.float32)\n",
    "        outs = model(text.to(device))\n",
    "        loss = lossfn(outs[..., -length:, :], targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    for i, (text, target) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            targets = F.one_hot(target[..., -length:], num_classes=num_digits).to(device, dtype=torch.float32)\n",
    "            outs = model(text.to(device))\n",
    "            loss = lossfn(outs[..., -length:, :], targets)\n",
    "            losses.append(loss)\n",
    "\n",
    "    epoch_loss = torch.Tensor(losses).mean().item()\n",
    "    print(\"Epoch {}, Current loss is {}\".format(epoch, epoch_loss))\n",
    "    loss_plot.append(epoch_loss)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4a55b5-959c-4815-9edc-827e391cb582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probs tensor([[9.8231e-01, 8.7392e-03, 2.4967e-03, 2.0364e-03, 4.4176e-03],\n",
      "        [1.9079e-03, 9.9072e-01, 4.4311e-03, 1.9536e-03, 9.8262e-04],\n",
      "        [3.3022e-03, 4.4532e-03, 9.7871e-01, 1.2126e-02, 1.4043e-03],\n",
      "        [3.3568e-03, 1.9370e-03, 2.9684e-03, 9.8899e-01, 2.7436e-03],\n",
      "        [2.7855e-03, 2.2410e-03, 1.9254e-03, 9.8899e-01, 4.0589e-03],\n",
      "        [2.9284e-03, 8.9401e-04, 1.1977e-03, 3.9823e-03, 9.9100e-01]])\n",
      "Sorted tensor([0, 1, 2, 3, 3, 4])\n",
      "\n",
      "Probs tensor([[0.9793, 0.0109, 0.0016, 0.0034, 0.0047],\n",
      "        [0.0050, 0.9858, 0.0013, 0.0045, 0.0034],\n",
      "        [0.0021, 0.9885, 0.0049, 0.0020, 0.0026],\n",
      "        [0.0023, 0.0034, 0.9842, 0.0039, 0.0062],\n",
      "        [0.0023, 0.0034, 0.9824, 0.0054, 0.0066],\n",
      "        [0.0029, 0.0021, 0.9270, 0.0506, 0.0174]])\n",
      "Sorted tensor([0, 1, 1, 2, 2, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    a = torch.tensor([[0, 1, 3, 4, 3, 2,    0, 1, 2, 3, 3]]) # Next digit is 4\n",
    "    out = model(a.to(device))\n",
    "    z = F.softmax(out[0, -length:, :], dim=-1)\n",
    "    print(\"Probs {}\\nSorted {}\\n\".format(z.cpu(), torch.argmax(z, dim=-1).cpu()))\n",
    "\n",
    "    a = torch.tensor([[0, 1, 2, 2, 1, 2,    0, 1, 1, 2, 2]]) # Next digit is 2\n",
    "    out = model(a.to(device))\n",
    "    z = F.softmax(out[0, -length:, :], dim=-1)\n",
    "    print(\"Probs {}\\nSorted {}\\n\".format(z.cpu(), torch.argmax(z, dim=-1).cpu()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960dc0fa-6b04-4b9d-b270-03f2fc02a104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
